{
  "context_id": "2025-10-29_04-52-54",
  "entity_type": "citizen",
  "entity_id": "felix",
  "created_at": "2025-10-29T03:52:54.051609+00:00",
  "messages": [
    {
      "role": "user",
      "timestamp": "2025-10-29T03:52:54.051837+00:00",
      "content": "Here’s a crisp brief you can hand to your **architect** and **developer** so they’re aligned on the why, what, and how. You’ll feed a JSON manifest with file paths (in order) to the CLI; the system will process each file, stream every action, open review Tasks, and resume safely on interruption—no dashboards, no “Document” nodes, zero keyword rules.\n\n---\n\n## Context (for both)\n\n* We’re converting a large, messy corpus into a **queryable, self-consistent conceptual graph** (Principle, Best_Practice, Mechanism, Behavior, Process, Metric, Task, …).\n* **No Document nodes** are created. Files are **transient input** only.\n* Everything is **embeddings + NLI** (no keyword heuristics).\n* Chunks are short: **~250 tokens** (hard cap 480).\n* Every write to the graph is **confirmed by a read-back**.\n* A **Quality pack** runs **every 5 files**, logging pass/warn/fail and opening Tasks on failures.\n* The orchestrator processes the corpus **strictly in the order** provided by a JSON manifest from the agent.\n\nExample manifest:\n\n```json\n{\n  \"files\": [\n    \"repo://docs/architecture/streaming.md\",\n    \"repo://docs/operability/latency_targets.md\",\n    \"repo://docs/mechanisms/delta_broadcast_v2.md\"\n  ]\n}\n```\n\n---\n\n## Goals (why this is worth doing)\n\n* Make the L2 organizational graph **complete enough** that subentities can inject accurate, minimal prompt packets without reading files.\n* Turn contradictions, gaps, and fuzzy relations into **explicit Tasks and typed links** with per-edge metadata (unit, claim, dimension, etc.).\n* Establish a **repeatable CLI loop**: ingest → map → link → lint → QA, fully observable via streaming logs and checkpointed in SQLite.\n\n---\n\n## What the architect should care about\n\n1. **Surface/Boundaries**\n\n   * Files are treated as **ephemeral**; only conceptual nodes and relationships persist.\n   * The CLI writes **only** via `graph.ensure_node/edge` (idempotent, read-back confirmed).\n   * Link metadata requirements live in `schema_registry/link_meta.yaml` (single source of truth).\n\n2. **Semantics (no schema changes)**\n\n   * Validation = **Metric + JUSTIFIES/REFUTES/MEASURES** to Behavior/Mechanism.\n   * Guide = **Process** (+ relations), not a new type.\n   * “Spec” is modeled as **Behavior** (concept), related to Mechanism via `DOCUMENTS` (if you already use concept→concept) or `RELATES_TO{role:'behavior_spec'}`.\n\n3. **Safety & Idempotence**\n\n   * Chunks small; max edges per chunk capped; duplicate edges suppressed per file.\n   * All writes have **two read-back retries**; otherwise the file is marked `failed` and can be resumed.\n   * No auto-creation of conceptual nodes: **Tasks** instead.\n\n4. **Quality cadence**\n\n   * Every 5 files: compute confirm rate, meta completeness, task density, coverage touch, contradiction rate, edges-per-chunk density.\n   * `pass|warn|fail` logged; `fail` opens a “QA remediation” Task with recommended knob tweaks.\n\n---\n\n## What the developer should implement\n\n**Tools directory** (already specced; you implement to spec):\n\n* `cli/mp.sh` — the one-liner entrypoint dispatching to Python.\n* `config.py` — env + thresholds (including chunk sizes and QA cadence).\n* `graph.py` — FalkorDB wrapper with **write→read confirmation** for nodes/edges.\n* `md_chunker.py` — 250-token chunks (cap 480), respects code blocks/tables, emits JSONL.\n* `ingest_docs.py` — walks manifest, computes file hash, updates `.mp_state.sqlite` (no graph writes).\n* `map_and_link.py` — embeddings + cross-encoder + NLI; proposes/creates edges with **per-edge metadata** from `link_meta.yaml`; opens Tasks for uncertainty/gaps.\n* `lint_graph.py` — structural checks (missing Behavior/Validation/Best_Practice/Process), meta-completeness checks; proposes safe fixes when `--fix`.\n* `process_corpus.py` — the orchestrator: reads the manifest, processes each file in order, **streams logs**, **checkpoints**, triggers QA every 5 files.\n* `status.py` — prints run state and next actions from SQLite.\n\n**Manifests (developer reads, not writes):**\n\n* `manifest.json` (from the agent), keys: `{ \"files\": [ \"<path1>\", \"<path2>\", ... ] }`.\n\n---\n\n## End-to-end Process (exact flow)\n\n1. **You hand them the specs + link_meta.yaml.**\n   They implement the tools exactly as specified.\n\n2. **Dry run on a small manifest (5–10 files).**\n\n   * Command:\n\n     ```\n     mp.sh process ./ --manifest manifest.json --dry-run --resume\n     ```\n   * Expect: JSONL stream like:\n\n     * `file_start`, then many `chunk` lines (~250 tokens each),\n     * `classify`, `edge_upsert` (status PROPOSED/CONFIRMED, with meta),\n     * `task_opened` for missing rungs/conflicts/meta,\n     * `file_done` summary,\n     * After the 5th file: a `qa_report` with `pass|warn|fail`.\n\n3. **Parameter tuning (if QA = warn/fail).**\n\n   * Adjust only knobs in config/CLI flags:\n\n     * `MIN_CONF_PROPOSE_LINK`, `MIN_CONF_AUTOCONFIRM`, `MIN_CONF_CREATE_TASK`,\n     * `ALPHA` (cross-encoder weight), `MAX_EDGES_PER_CHUNK`.\n   * Rerun the same manifest with `--resume` (done files are skipped, failed are retried).\n\n4. **Main run (full manifest).**\n\n   * Command:\n\n     ```\n     mp.sh process ./ --manifest manifest.json --resume --min-confidence 0.72\n     ```\n   * The tool processes **in your order**, opens Tasks for humans where needed, and **persists state** in `.mp_state.sqlite`.\n   * Every 5 files, it emits a QA report and (if fail) a remediation Task.\n\n5. **Human review loop.**\n\n   * Humans/agents work off the **Tasks** created (e.g., “Write Behavior Spec for X”, “Establish validation for Y”, “Resolve MEASURES conflict…”).\n   * No dashboards; the CLI stream + Tasks is your control surface.\n\n6. **Reruns for convergence.**\n\n   * `mp.sh process ... --resume` until there are no `failed` files and QA stabilizes at `pass` or occasional `warn`.\n\n7. **Ongoing maintenance.**\n\n   * When new files appear, the agent updates `manifest.json`; you rerun `process` with `--resume`.\n   * The linter can be run ad-hoc:\n\n     ```\n     mp.sh lint --scope touched --fix\n     ```\n\n---\n\n## Operational details they must follow\n\n* **No Document nodes:** never call anything that would create or depend on a `Document` label.\n* **Anchors are transient:** `md_chunker` emits `section_path` + `line_span` only for logging/context.\n* **Zero keyword heuristics:** `map_and_link` must rely solely on embeddings/cross-encoder/NLI and the link metadata registry for required fields.\n* **Per-edge metadata:** every relationship must carry `r.meta` that satisfies `required` fields from `link_meta.yaml`. Missing fields → open “Complete metadata” Task (or fix if derivation confidence ≥ 0.9).\n* **Read-back confirmation:** every write gets a read-back; failures mark the file `failed`.\n* **Chunk sizes:** target ~250 tokens, max 480; oversized code blocks are skipped with a `lint_warning`.\n* **QA cadence:** exactly every 5 `done` files; log `qa_report` (and `qa_warn/qa_fail`), persist to the `qa` table.\n\n---\n\n## Typical commands (for them to copy/paste)\n\n* Process in manifest order:\n\n  ```\n  mp.sh process . --manifest manifest.json --resume\n  ```\n* Process only first N files:\n\n  ```\n  mp.sh process . --manifest manifest.json --max-files 20 --resume\n  ```\n* Lint recently touched nodes and propose safe fixes:\n\n  ```\n  mp.sh lint --scope touched --fix\n  ```\n* Show status + latest QA:\n\n  ```\n  mp.sh status --json\n  ```\n\n---\n\n## Definition of Done (for this phase)\n\n* The manifest completes with **0 `failed` files**.\n* QA over the last batch: **`pass`**, or at worst `warn` with a created “QA trend watch” Task and a plan.\n* No Mechanism remains without a **Behavior** relation nor **Process** relation.\n* Every Behavior has at least one **MEASURES** (Metric) or a Task to create it.\n* All edges written since the last run satisfy `required` metadata in `link_meta.yaml` (or have open “Complete metadata” Tasks).\n\n---\n\nWhen they’re ready, the agent can rotate manifests (new docs, renames) and the loop keeps rolling. The beauty here is boring: a single CLI, streamed logs you can grep, hard confirmations, and a graph that gets more coherent every five files.\n"
    }
  ],
  "last_updated": "2025-10-29T03:52:54.051854+00:00",
  "message_count": 1
}