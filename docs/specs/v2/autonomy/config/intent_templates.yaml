# Intent Templates Configuration
# Version: 1.0
# Created: 2025-10-25
# Purpose: Template definitions for L2 autonomy intent matching and mission assignment
# Owner: Ada (orchestration) + Atlas (implementation)

# ==============================================================================
# Template Definitions
# ==============================================================================

templates:
  # ----------------------------------------------------------------------------
  # 1. Reply to Human (Fast Lane for DMs/Partner Messages)
  # ----------------------------------------------------------------------------
  - id: intent.reply_to_human
    version: "1.1"
    description: "Fast-lane routing for human DMs (Telegram, FE messages) with prepare-then-reply execution and merge windows for bursty messages"

    # Matching Conditions
    match:
      source_types:
        - "human_dm.telegram"    # Direct Telegram messages
        - "human_dm.frontend"    # Frontend message panel
        - "human_dm.email"       # Email (if configured)

      # Must specify target citizen in metadata
      required_metadata:
        - "to_citizen"           # Which citizen is being addressed
        - "conversation_id"      # Thread context

      # No quantile gate - all human DMs get through
      severity:
        min: 0.0                 # Accept all severities

    # Routing Rules (explicit citizen addressing)
    routing:
      - condition:
          metadata.to_citizen: "felix"
        assignee: "felix"
        reason: "Direct message to Felix"

      - condition:
          metadata.to_citizen: "ada"
        assignee: "ada"
        reason: "Direct message to Ada"

      - condition:
          metadata.to_citizen: "atlas"
        assignee: "atlas"
        reason: "Direct message to Atlas"

      - condition:
          metadata.to_citizen: "iris"
        assignee: "iris"
        reason: "Direct message to Iris"

      - condition:
          metadata.to_citizen: "luca"
        assignee: "luca"
        reason: "Direct message to Luca"

      - condition:
          metadata.to_citizen: "victor"
        assignee: "victor"
        reason: "Direct message to Victor"

      # Default: route to Ada for triage
      - condition: {}
        assignee: "ada"
        reason: "Unaddressed DM routed to Ada for triage"

    # Merge Window (batch bursty messages)
    merge_window:
      enabled: true
      window_duration_sec: 3  # Wait up to 3 seconds for follow-up messages
      max_messages_to_merge: 5  # Batch up to 5 messages into one mission
      merge_strategy: "chronological"  # Present messages in order received

    # Acceptance Gates
    acceptance:
      # Auto-execute for most DMs (prepare-then-reply execution)
      auto_execute:
        - condition: "metadata.business_impact NOT IN ['sev1', 'production_deploy']"
        - condition: "origin_chain_depth == 0"  # Not self-observation
        - condition: "merged_message_count <= 5"  # Reasonable batch size

      # ACK required for high-impact asks
      ack_required:
        - condition: "metadata.business_impact IN ['sev1', 'production_deploy']"
          reason: "High-impact requests require explicit approval"
        - condition: "merged_message_count > 5"
          reason: "Large message batches need review to prevent overwhelming citizen"
        - condition: "content CONTAINS 'deploy' OR content CONTAINS 'production'"
          reason: "Production changes require ACK"

    # Mission Configuration (prepare-then-reply execution)
    mission:
      template: |
        ## Human Message(s)

        **From:** {actor}
        **Channel:** {metadata.channel}
        **Conversation:** {metadata.conversation_id}
        **Timestamp:** {timestamp_ms}
        **Merged Messages:** {merged_message_count}

        **Message(s):**
        ```
        {merged_content}
        ```

        ## Your Mission (Prepare-Then-Reply)

        **⚠️ IMPORTANT:** Do NOT reply immediately. Prepare a complete response first.

        ### Execution Flow:

        1. **Context Gathering (Streamline runs automatically before this mission)**
           - Person card (name, expertise, recent interactions)
           - Last 20 messages in conversation
           - Active tasks/goals for this person
           - Relevant organizational policies

        2. **Research & Preparation**
           - Use Streamline context to understand full picture
           - Search L1 (personal) + L2 (organizational) graphs for relevant information
           - Gather evidence, verify claims, check current system state
           - Identify what work (if any) needs to happen

        3. **Reply (After Preparation Complete)**
           - Provide comprehensive, well-researched response
           - Cite sources from context/graphs (e.g., "According to SYNC.md entry from 2025-10-25...")
           - If work needed: Propose concrete plan + create follow-up intent
           - If uncertain: Ask clarifying questions with context about why uncertain

        4. **Bounded Execution (Continue Score)**
           - Mission continues while Continue Score > threshold
           - Continue Score driven by: WM stability, criticality state, health.phenomenological, PoV trend
           - Q: What exact formula? What quantile-based gate thresholds?
           - When score drops below threshold, wrap up and emit micro_session.done

        5. **Follow-Up Work (If Needed)**
           - Create separate intent for substantial work (don't block reply on implementation)
           - Reply can BE a mission asking you to do something (prepare + act)

        ## Reply Guidelines

        - **Be thorough** (not artificially brief - use the context you gathered)
        - **Cite evidence** from Streamline context, graphs, docs, code
        - **No hallucinations** - if uncertain, explicitly state uncertainty with reasoning
        - **Promise follow-up** if substantial work needed (create intent in graph)
        - **Telegram-friendly** formatting (markdown, no complex tables)

        ## Dynamic Toolbox

        Available tools for this mission (based on channel={metadata.channel}):
        {dynamic_toolbox}

        Q: How is dynamic toolbox generated? MCP budget <6 tools. Unmount on micro-session end.

        ## Verification Criteria

        - ✅ Reply sent (after preparation, not immediately)
        - ✅ Human's question answered with citations
        - ✅ Follow-up intent created if work required
        - ✅ No hallucinations (all claims backed by evidence or marked as uncertain)
        - ✅ micro_session.done emitted when Continue Score drops

      # Expected outcome
      expected_outcome:
        reply_sent: true
        reply_latency_target_sec: 180  # 3 minutes (allows for preparation)
        micro_session_completion: true
        verification_query: |
          MATCH (s:Stimulus {stimulus_id: $stimulus_id})
          MATCH (r:Response)-[:RESPONDS_TO]->(s)
          MATCH (e:Event {type: 'micro_session.done', session_id: $session_id})
          WHERE r.timestamp_ms < $stimulus_timestamp + 180000
          RETURN r.timestamp_ms as reply_timestamp, e.timestamp_ms as completion_timestamp
        success_condition: "reply_timestamp EXISTS AND completion_timestamp EXISTS"

      # Time limits
      sla:
        max_duration_minutes: 10  # Up to 10 min for preparation + reply
        verification_window_minutes: 0  # No post-reply monitoring

    # Metadata for tracking
    metadata:
      priority_lane: "rapid_response"  # Dedicated fast lane
      cooldown_window_sec: 0  # No cooldown for human DMs
      merge_keys: ["conversation_id", "to_citizen"]  # Merge by conversation + recipient
      max_fanout: 1

    # Open Questions (to be refined)
    questions:
      - "Q: Where does Streamline service live? orchestration/services/streamline_service.py?"
      - "Q: What's the exact Cypher query pattern for person card + last 20 messages?"
      - "Q: Continue Score formula - which specific engine signals? What quantile thresholds?"
      - "Q: Hook integration - where do before_message, after_message hooks run?"
      - "Q: Dynamic toolbox generation - how does it select <6 MCP tools based on mission metadata?"
      - "Q: Micro-session integration - how does canonical thread consume micro_session.done events?"
      - "Q: CLAUDE_DYNAMIC.md vs CLAUDE.md - when does it switch to full CLAUDE.md?"

  # ----------------------------------------------------------------------------
  # 2. Fix Incident (Console/Log Errors → Citizen Remediation)
  # ----------------------------------------------------------------------------
  - id: intent.fix_incident
    version: "1.0"
    description: "Route operational incidents (console errors, log errors, crashes) to appropriate citizen for autonomous remediation"

    # Matching Conditions
    match:
      source_types:
        - "error.console"     # Frontend console errors (console_beacon)
        - "error.log"         # Backend log errors (log_tail)
        - "process.crash"     # Process failures (ProcessExec forensics)

      severity:
        min: 0.5              # Only ERROR/CRITICAL (not WARN)
        quantile_gate: 0.75   # Must be above P75 of recent error severity

      # Optional: match specific error patterns
      patterns:
        - regex: "TypeError|ReferenceError|null is not"
          description: "JavaScript runtime errors"
        - regex: "ConnectionError|TimeoutError|ECONNREFUSED"
          description: "Network/connection failures"
        - regex: "AssertionError|ValidationError"
          description: "Data validation failures"

    # Routing Rules (who gets assigned based on signal metadata)
    routing:
      - condition:
          service: ["dashboard", "app/"]
        assignee: "iris"
        reason: "Frontend/dashboard errors go to Iris"

      - condition:
          service: ["websocket_server", "consciousness_engine", "mechanisms"]
        assignee: "atlas"
        reason: "Backend infrastructure errors go to Atlas"

      - condition:
          service: ["guardian", "launcher", "mpsv3_supervisor"]
        assignee: "victor"
        reason: "Ops/process management errors go to Victor"

      - condition:
          source_type: "process.crash"
        assignee: "victor"
        reason: "All crashes route to Victor for forensics"

      # Default fallback
      - condition: {}
        assignee: "atlas"
        reason: "Default backend triage"

    # Acceptance Gates (when to auto-execute vs require ACK)
    acceptance:
      # Auto-execute conditions (all must be true)
      auto_execute:
        - condition: "severity < 0.8"  # Not sev1 (sev1 = 0.8-1.0)
        - condition: "service NOT IN ['falkordb', 'mpsv3_supervisor']"  # Not sentinel-critical
        - condition: "origin_chain_depth == 0"  # Not self-observation cascade
        - condition: "duplicate_count == 0"  # Not a recurring flood

      # ACK required conditions (any true → require human approval)
      ack_required:
        - condition: "severity >= 0.8"
          reason: "Sev1 incidents require human visibility"
        - condition: "service IN ['falkordb', 'mpsv3_supervisor']"
          reason: "Sentinel-critical services require careful handling"
        - condition: "origin_chain_depth >= 2"
          reason: "Deep self-observation chains must be vetted"
        - condition: "duplicate_count >= 5"
          reason: "Recurring failures may indicate systemic issue"

    # Mission Configuration
    mission:
      template: |
        ## Incident Report

        **Error:** {metadata.message}
        **Service:** {metadata.service}
        **Severity:** {severity} (sev{severity_level})
        **Timestamp:** {timestamp_ms}

        **Stack Trace:**
        ```
        {metadata.stack}
        ```

        **Context:**
        - File: {metadata.file_path}:{metadata.line_number}
        - Recent similar incidents: {duplicate_count}
        - Origin: {source_type} via {metadata.event_source}

        ## Your Mission

        1. **Diagnose:** Review the error and stack trace. Identify root cause.
        2. **Fix:** Implement a fix that addresses the root cause (not just symptoms).
        3. **Verify:**
           - Run relevant tests (unit/integration)
           - Check logs for recurrence (5 min monitoring window)
           - Confirm error count drops to zero
        4. **Document:** Update SYNC.md with findings and fix.

        ## Verification Criteria

        - ✅ Error no longer appears in logs/console (5 min clean window)
        - ✅ Tests pass (exit code 0)
        - ✅ No new errors introduced (regression guard)
        - ✅ Root cause documented in SYNC.md

      # Expected outcome for verification
      expected_outcome:
        error_count_drops: true
        verification_query: |
          MATCH (s:Stimulus {source_type: $source_type, metadata.service: $service})
          WHERE s.timestamp_ms > $fix_timestamp
          RETURN count(s) as post_fix_count
        success_condition: "post_fix_count == 0"

      # Time limits
      sla:
        max_duration_minutes: 30  # Citizen has 30 min to fix
        verification_window_minutes: 5  # Monitor for 5 min post-fix

    # Metadata for tracking
    metadata:
      priority_lane: "incidents"
      cooldown_window_sec: 300  # 5 min cooldown for same error
      merge_keys: ["service", "message"]  # Dedupe by service + message
      max_fanout: 1  # Only create one intent per unique error

  # ----------------------------------------------------------------------------
  # 2. Sync Docs/Scripts (Code↔Doc Drift → Counterpart Update)
  # ----------------------------------------------------------------------------
  - id: intent.sync_docs_scripts
    version: "1.0"
    description: "Detect code↔doc drift and auto-sync counterparts to maintain coherence"

    # Matching Conditions
    match:
      source_types:
        - "code_change"      # git_watcher detects code change (SCRIPT_MAP.md)
        - "doc_change"       # git_watcher detects doc change

      # Drift threshold
      drift_hours:
        min: 24              # Only act if drift >24 hours
        quantile_gate: 0.5   # Must be above median drift duration

    # Routing Rules
    routing:
      - condition:
          source_type: "code_change"
          counterpart_type: "doc"
        assignee: "ada"
        reason: "Code changes → Ada updates documentation"

      - condition:
          source_type: "doc_change"
          counterpart_type: "code"
        assignee: "atlas"
        reason: "Doc changes → Atlas syncs implementation"

      # Default
      - condition: {}
        assignee: "ada"
        reason: "Default documentation triage"

    # Acceptance Gates
    acceptance:
      # Auto-execute (safe operations)
      auto_execute:
        - condition: "drift_hours >= 24 AND drift_hours < 168"  # 1 day - 1 week
        - condition: "file_size_kb < 50"  # Small files only
        - condition: "origin_chain_depth == 0"  # Not cascaded

      # ACK required
      ack_required:
        - condition: "drift_hours >= 168"  # 1 week+ stale = review needed
        - condition: "file_size_kb >= 50"  # Large files need review
        - condition: "counterpart_path CONTAINS 'architecture' OR counterpart_path CONTAINS 'CRITICAL'"
        reason: "Architecture docs need careful review"

    # Mission Configuration
    mission:
      template: |
        ## Code/Doc Drift Detected

        **Source:** {metadata.file_path}
        **Counterpart:** {metadata.counterpart_path}
        **Drift Duration:** {metadata.drift_duration_hours} hours ({metadata.drift_duration_days} days)
        **Change Type:** {source_type}

        **Diff Excerpt:**
        ```diff
        {metadata.diff_excerpt}
        ```

        ## Your Mission

        1. **Review:** Understand what changed in the source file.
        2. **Sync:** Update the counterpart file to reflect changes:
           - If code_change → update docs to match new implementation
           - If doc_change → update code to match new spec
        3. **Verify:**
           - Ensure counterpart accurately reflects source
           - Check for broken references or outdated examples
           - Run tests if code was modified
        4. **Document:** Add entry to SYNC.md noting sync completion.

        ## Verification Criteria

        - ✅ Counterpart file updated and committed
        - ✅ No broken references or examples
        - ✅ Tests pass (if code modified)
        - ✅ SYNC.md updated

      expected_outcome:
        counterpart_updated: true
        verification_query: |
          MATCH (f:File {name: $counterpart_path})
          WHERE f.metadata.mtime > $sync_timestamp
          RETURN f.metadata.mtime as last_modified
        success_condition: "last_modified > sync_timestamp"

      sla:
        max_duration_minutes: 45  # 45 min to sync
        verification_window_minutes: 0  # No post-sync monitoring

    metadata:
      priority_lane: "sync"
      cooldown_window_sec: 3600  # 1 hour cooldown per file pair
      merge_keys: ["file_path", "counterpart_path"]
      max_fanout: 1  # One intent per file pair

# ==============================================================================
# Template Metadata
# ==============================================================================

metadata:
  schema_version: "1.0"
  last_updated: "2025-10-25"
  owner: "Ada Bridgekeeper (orchestration)"

  # Validation rules
  validation:
    required_fields: ["id", "version", "match", "routing", "acceptance", "mission"]
    allowed_source_types:
      - "error.console"
      - "error.log"
      - "process.crash"
      - "code_change"
      - "doc_change"
      - "runtime.anomaly"
      - "screenshot"

  # Usage notes
  notes: |
    Intent templates define:
    1. Match conditions (which signals trigger this intent)
    2. Routing rules (which citizen gets assigned)
    3. Acceptance gates (auto-execute vs ACK required)
    4. Mission template (instructions for the citizen)
    5. Verification criteria (how to confirm success)

    Templates are evaluated in order. First match wins.

    ACK policies ensure human oversight for:
    - High severity incidents (sev1/sev2)
    - Sentinel-critical services (FalkorDB, supervisor)
    - Deep self-observation chains (depth >= 2)
    - Recurring failures (duplicate_count >= threshold)

    Auto-execute is safe for:
    - Low-medium severity incidents
    - Non-critical services
    - First-occurrence errors
    - Code/doc sync for small files with moderate drift

  # Architectural Decisions (2025-10-25)
  architecture:
    notes: |
      Key corrections from architectural review:

      1. **No L2 Org Agent**: Only citizens (L1) act. L2 can have decision threads (artifacts) but no agent persona.

      2. **Prepare-Then-Reply for DMs**: Not reply-first. Citizens gather context via Streamline, research,
         then reply. Allows for thorough preparation before responding.

      3. **Merge Windows for Bursty Messages**: 2-5 second windows to batch rapid-fire messages (e.g., 5 messages → 1 answer).
         Prevents overwhelming citizens with separate missions for each message in a burst.

      4. **Streamline Context Injection**: Separate service (NOT part of Consciousness Engine) that runs L1+L2
         graph traversal before each mission. Updates CLAUDE_DYNAMIC.md (currently) with person card, last 20 messages,
         active tasks, policies. Will migrate to full CLAUDE.md when ready.

      5. **Bounded Execution via Emotion/Energy**: Continue Score driven by engine signals (WM stability, criticality,
         health.phenomenological, PoV trend). NOT fixed turn limits or time budgets. Quantile-based gates.

      6. **Dynamic Toolbox per Mission**: Mission metadata determines which MCP tools to mount (e.g., channel="telegram"
         → /send_telegram, /get_telegram_thread). Keep budget <6 tools. Unmount on micro_session end.

      7. **Micro-Session Integration**: Each mission runs as WM shard, emits micro_session.done when Continue Score drops.
         Canonical thread integrates completion as stimulus.

      8. **Citizens AND People as Actors**: Not just citizens. Humans (people) also act in the system. No L2 org agent.

  # Open Questions (To Be Refined)
  open_questions:
    streamline:
      - "Where does Streamline service live? orchestration/services/streamline_service.py?"
      - "What's the exact Cypher query pattern for L1+L2 traversal (person card + last 20 messages + active tasks + policies)?"
      - "Which node/link type enums should Streamline use for queries?"
      - "When does CLAUDE_DYNAMIC.md migrate to full CLAUDE.md?"

    continue_score:
      - "What's the exact formula for Continue Score?"
      - "Which specific engine signals map to Continue Score (WM stability, criticality, health.phenomenological, PoV trend)?"
      - "What quantile-based gate thresholds? (e.g., 'continue while score > P25 of recent scores'?)"
      - "How is the threshold adjusted over time (learning)?"

    hooks:
      - "Where do before_message, after_message, before_stop hooks run?"
      - "What's the hook execution model (blocking, async, parallel)?"
      - "What data structure do hooks receive (full stimulus envelope, just metadata)?"
      - "How do hooks call Streamline service?"

    dynamic_toolbox:
      - "How is dynamic toolbox generated from mission metadata?"
      - "What's the mapping from channel/service → MCP tools?"
      - "How does unmounting work on micro_session end?"
      - "Where are outbound channel wrappers defined (/send_telegram, /send_email)?"

    micro_sessions:
      - "How does canonical thread consume micro_session.done events?"
      - "What format is the integration stimulus (full transcript, summary, just outcome)?"
      - "How are WM shards created for micro-sessions?"
      - "How does the citizen's main thread know about micro-session outcomes?"
