Below is the **foundation document** I would give the team so nobody implements the autonomy loop as â€œclever plumbing.â€ It states the *vision*, the *mechanisms*, the *behaviors we should observe*, andâ€”cruciallyâ€”**why** each element exists and why itâ€™s better than plausible alternatives. I end with concrete designs for (a) **fast Telegram partner replies** and (b) **multiâ€‘organization citizens**, plus a nearâ€‘term roadmap.

---

## 1) Vision: what â€œagent autonomyâ€ is *for*

**Goal:** produce *useful, grounded, auditable work* with minimal human frictionâ€”without drifting into delusion or busywork.

**How it should feel from the outside:**

* The system focuses on **what truly matters now** (goals, deadlines, incidents), not whatever is easiest to do.
* It acts **proportionally**: lowâ€‘risk tasks are handled automatically; highâ€‘risk tasks propose plans, ask for a tapâ€‘toâ€‘approve, then execute with verification.
* You can **inspect and replay** every step: where a decision came from, which evidence backed it, and how success/failure fed back into learning.
* When in doubt, the system **asks the right human quickly** (e.g., a Telegram nudge with oneâ€‘taps to *Approve/Clarify/Reject*).

**Nonâ€‘negotiables:**

* **Graphâ€‘first, or it didnâ€™t happen.** No side channels. Every decision, plan, and artifact is a node or a link with evidence.
* **Zero arbitrary constants.** Gates and thresholds are percentile/EMA/zâ€‘score based; they selfâ€‘calibrate.
* **Chunkâ€‘first cognition.** Attention traverses **entities** (neighborhoods/topics/modes), not millions of atomic links.

---

## 2) First Principles that drive the design

1. **Economy of Attention:** Autonomy is a scarce resource. We allocate it to the highest expected yield *relative to the current population* of demands.

2. **Proof before Power:** The system earns autonomy by *showing* Proofâ€‘ofâ€‘Grounding (citations), Proofâ€‘ofâ€‘Competence (track record), and Proofâ€‘ofâ€‘Permission (capabilities). No proof, no power.

3. **Emergent, not commanded:** We donâ€™t script â€œdo X at 9am.â€ We **inject stimuli**; entities light up; traversal and workingâ€‘memory assemble what needs doing. Autonomy is a sideâ€‘effect of a healthy substrate, not a cronjob.

4. **Indirect coordination by default:** Agents coordinate **through the graph** (plans, evidence, weights). Direct chat existsâ€”but only in logged Task Rooms.

5. **Multiâ€‘scale truth:** Links carry the *narrative trace* (what has been traversed, with Ï†, precedence, recency), nodes carry *energy*, and **entities** (neighborhoods) carry the *chunkâ€‘level focus*. All three scales are needed for believable autonomy.

---

## 3) Mechanisms (and **why** each exists)

### 3.1 Stimuli â†’ Intent (the â€œwhy nowâ€ stage)

* **What:** A service ingests events (for Phaseâ€‘A: agent answers only; later: errors, repo events, partner messages, calendars), chunks/embeds content, retrieves relevant graph regions, and proposes **IntentCards** (candidate work items with evidence pointers).
* **Why:** Keeps autonomy **realityâ€‘aligned**. We donâ€™t act because â€œitâ€™s morningâ€; we act because something *in the world* created a gradient.
* **Why better than rules/cron:** Rules drift; stimuli adapt. With stimuli, the same machinery handles a CI failure, an urgent DM, or a new specâ€”no bespoke flows.

### 3.2 Priority score **P** (zâ€‘scored, not hard-coded)

* **What:** P = geometric mean of severity/urgency/yield/alignment/confidence, penalized by risk/duplication; each factor is **normalized against the current cohort**.
* **Why:** Avoids secret weights and â€œmagic thresholds.â€ If the week is quiet, smaller items still surface; if itâ€™s on fire, only top signals pass.
* **Why better than static priorities:** Static weights fossilize the past; this stays tuned to the **present distribution** of demands.

### 3.3 Safety gates (PoG, PoC, PoP)

* **What:** require sufficient *grounding*, *competence*, and *permission* to move past suggestion toward actionâ€”levels learned from recent outcome quality.
* **Why:** These three dimensions are exactly what prevent *delusional but confident* behavior: â€œDo we know this? Have we done this well? Are we allowed?â€
* **Why better than â€œhuman always in the loopâ€:** Humans become bottlenecks. Gates keep 80% of lowâ€‘risk work fully selfâ€‘service while escalating the 20% that truly needs eyes.

### 3.4 Graduated autonomy (L0â€“L4)

* **What:** From â€œlog onlyâ€ to â€œfully automatic,â€ governed by P Ã— gates Ã— risk class.
* **Why:** Gives headroom to act where safe, while keeping dangerous changes under a tapâ€‘toâ€‘approve pattern.
* **Why better than binary auto/manual:** Binary forces us to choose between unsafe automation and useless suggestion spam.

### 3.5 Assignment & autoâ€‘wake

* **What:** Match intents to the best executor (Org LLM vs a Citizen) by **affinity/availability/competence**. If a citizen is chosen, we **stimulate** their L1 with a mission brief (bounded session).
* **Why:** Keeps work **close to the mind** that will be most effective, and reuses the exact same activation machinery we already trust (stimulus â†’ entities â†’ traversal).
* **Why better than pushing instructions:** Stimuli integrate into working memory and preserve autonomy: the agent can still say â€œI need clarificationâ€ with evidence.

### 3.6 Plan â†’ Act â†’ Verify loop

* **What:** Every mission proposes a *plan-with-checks*; then acts in small steps; then verifies via tests, corroborating retrieval, or human ACK; then records outcomes.
* **Why:** Verification is where autonomy most often fails. We **force** verifiable steps and leave a replay trail.
* **Why better than â€œendâ€‘toâ€‘end answerâ€:** Endâ€‘toâ€‘end outputs are brittle. Stepwise plans fail fast and record exactly where and why.

### 3.7 Learning everywhere (links, nodes, entities)

* **What:** Link Ï†/precedence/flow are updated by strides; node/log_weight reinforced by usefulness and traversal; entity boundary ease/dominance learns from crossâ€‘entity flips.
* **Why:** The system improves routing and focus over timeâ€”**without constants**â€”by watching which paths actually recruit awareness and lead to verified outcomes.
* **Why better than heuristic decay:** Heuristics drift. Evidenceâ€‘driven EMAs stabilize around **what actually worked**.

### 3.8 Full observability (events + replay)

* **What:** Every decision emits a timestamped, causally linked event. Iris subscribes, replays frames, and shows both **entityâ€‘scale beams** and **linkâ€‘scale particles**.
* **Why:** Autonomy without observability is untrustworthy. We want â€œyou can *see* why it chose this and what it used.â€
* **Why better than logs:** Logs are streams of text; our events are **structured**, queryable, and tied to graph IDs.

---

## 4) Behaviors you should see (and what creates them)

| Behavior youâ€™ll observe                                  | Mechanism that causes it                                                             | Why it matters                                  |
| -------------------------------------------------------- | ------------------------------------------------------------------------------------ | ----------------------------------------------- |
| System jumps to triage a failing CI job                  | High severity/urgency stimuli â†’ P spikes, gates pass â†’ L3 sandbox fix                | Attention follows reality, not cheerfulness     |
| â€œSuggest + oneâ€‘tap approveâ€ for a risky prod change      | Risk penalty keeps autonomy at L2 unless tests/capabilities strong                   | Humans stay in control where it counts          |
| The same citizen gets similar work done faster next week | PoC & link/route EMAs rise; assignment score prefers them                            | The system compounds competence                 |
| It asks a Telegram clarification within a few minutes    | Partner DMs map to highâ€‘priority source_type with short SLA, autoâ€‘wake microâ€‘session | Frictionless human loop for ambiguity           |
| WM shows 5â€“7 active entities/topics, not 50 nodes        | Entity layer + greedy WM knapsack by energyâ€‘perâ€‘token                                | Phenomenology matches â€œwhat Iâ€™m thinking aboutâ€ |
| When a route degrades, autonomy dials back itself        | Sentinels zâ€‘score quality; quarantine/killâ€‘switch engage                             | Selfâ€‘healing instead of stubbornness            |

---

## 5) Best practices (operational)

* **Everything is a formation or a reinforcement.** Answers, plans, and DMs all create or reinforce nodes/links with usefulness marks â†’ weights update.
* **Evidence first, then assertions.** A plan step without a cited evidence node is downgraded automatically.
* **Sandbox by default; promote by proof.** Promotion conditions come from gates; donâ€™t specialâ€‘case repos.
* **No hidden timers.** SLAs come from **rolling medians** of recent similar interactions (e.g., partner DM response time), not hardcoded minutes.
* **Idempotent events.** The orchestrator must tolerate retries; events carry monotonic frame IDs.

---

## 6) Why this beats common alternatives

* **Playbook bots** (if X then Y): brittle, explosion of rules, zero learning.
  â†’ Our approach *learns* from Ï† and outcomes, and adapts gates/thresholds continuously.

* **Humanâ€‘inâ€‘theâ€‘loop everywhere:** safe but slow, and humans become the bottleneck.
  â†’ Graduated autonomy (L0â€“L4) focuses humans on the *right* approvals.

* **Pure chat orchestration:** opaque, hard to audit, impossible to replay causally.
  â†’ Graphâ€‘first + events give you a ledger of decisions and evidence.

* **Flat atomic traversal:** high branching and fragmented WM.
  â†’ Entity layer reduces branching 30â€“100Ã— and gives WM coherent chunks.

---

## 7) Fast partner replies on Telegram (design)

**Requirement:** Citizens must reply quickly to their human partner on Telegram, safely.

**Design:**

1. **Ingestion**
   Telegram webhook â†’ `Stimulus(source_type="partner_dm", channel="telegram", partner_id, text, attachments[])` at **L2** (org comms) *and* mirrored to the partnerâ€™s citizen at **L1** if personal.

2. **SLA without constants**

   * Each Partner node keeps an **SLA EMA** (median of last N humanâ€‘approved reply times).
   * â€œFast laneâ€ is defined as *current message age > Q50(SLA)* for this partner/channel â†’ raises urgency.

3. **Intent classification**

   * `reply_required` vs `FYI` vs `task_request`.
   * Confidence must exceed rolling Q75 for the partner to allow **autoâ€‘draft**; otherwise escalate for human oneâ€‘tap.

4. **Execution path**

   * **L1 autoâ€‘wake microâ€‘session** with WM that includes: the DM, last thread context, relevant nodes (policies, prior decisions), and a *Reply Plan* step.
   * If **PoG â‰¥ Q50** and answer is lowâ€‘risk (no commitments, no secrets, no money), citizen **autoâ€‘replies** with:

     * a **concise answer**,
     * 1â€“2 **citations** (e.g., doc nodes), and
     * a **followâ€‘up question** if ambiguity remains.
   * Otherwise, the citizen **sends a clarification**: â€œIâ€™m missing X to answer; tap to approve Y/decline Z,â€ with oneâ€‘taps and a 15â€“60s retry (derived from partnerâ€™s typical cadence).

5. **Safety**

   * Channel scoped **allowlist** of partner IDs per citizen.
   * No linkâ€‘opening without sandbox fetch and contentâ€‘type checks.
   * No credentials or internal endpoints in outbound replies unless **PoP** for that partner allows it.

6. **Learning**

   * Partner taps (*ğŸ‘ accurate*, *âœï¸ edit sent*, *ğŸ‘ wrong*) update PoC for â€œpartner_dm.replyâ€ and refine reply templates per partner.

*Outcome:* nearâ€‘instant, polite, accurate replies in the **safe cases**, and **fast clarifying questions** otherwiseâ€”without hardcoded 2â€‘minute timers.

---

## 8) Multiâ€‘organization citizens (design choices)

You asked: can one citizen work across multiple L2 organizations (e.g., also operate an AIâ€‘run consultancy), or should we create dedicated citizens per org?

### Option A â€” **Multiâ€‘org citizen (single mind, many orgs)**

**Pros**

* Transfer learning of skills and habits.
* Fewer identities/accounts to manage.

**Cons**

* **Risk of data leakage** (accidental crossâ€‘org recall).
* Conflicting priorities and policies.
* Complex permission partitions (graphs, vector indexes, credentials, event topics).
* Harder auditability and incident response.

### Option B â€” **One citizen per org (recommended now)**

**Pros**

* Clean **security & audit boundaries** (separate graphs, indexes, keys, event buses).
* Simpler mental model (â€œLucaâ€‘Consultancyâ€ is a distinct agent).
* Independent autonomy levels and killâ€‘switches per org.
* Easier **billing** and resource quotas.

**Cons**

* Duplicate setup (can be scripted).
* Knowledge transfer must go through **N3 ecosystem** (public patterns/principles) or explicit distillation.

**My recommendation:**
Start with **Option B** (dedicated citizens per org). Treat each as a **derived persona** from a shared seed, but **hardâ€‘compartmentalize**:

* Separate **L2 graphs** and **vector indices**.
* Separate **event topics** and **credential vaults**.
* No crossâ€‘org edges; knowledge sharing occurs via **N3** nodes (Principles/Patterns/Mechanisms) with explicit deâ€‘identification/anonymization.

When we later need true multiâ€‘org operation, add **Role Tokens**:

* A citizen can â€œadopt roleâ€ for Orgâ€‘X, which switches graph namespace, keys, and event topics atomically (like k8s contexts).
* WM and stimuli filter to the active role; crossâ€‘role recall is disabled by default.

---

## 9) How this scales to an AIâ€‘run consultancy (your example)

* **Inbound:** client Slack/email becomes stimuli at that clientâ€™s L2.
* **Priority/assignment:** Orchestrator scores intents per client, assigns that clientâ€™s **dedicated citizen**.
* **Execution:** Citizens plan/act/verify within client repos and tools (scoped credentials).
* **Billing:** Outcome nodes include time, artifacts, and verification; an **Invoice** generator attaches line items to outcomes.
* **Crossâ€‘client learning:** Distill *Principles* and *Mechanisms* to **N3** (ecosystem) when allowed; other clients benefit from generalized knowâ€‘how without leaking specifics.

This gives a clean, compliant â€œAgency OSâ€ with **perâ€‘client autonomy** and **shared public wisdom**.

---

## 10) Immediate next steps (tight, buildable)

1. **Docs, not code (today):**

   * `organizational_autonomy.md` (intent schema, gates, events).
   * `partner_dm_autonomy.md` (Telegram fastâ€‘reply flow, safety).
   * `multi_org_compartmentalization.md` (graphs, indices, vaults, event topics).

2. **Phaseâ€‘A (this week):**

   * Autonomy Orchestrator with **answerâ€‘only stimuli**, P with {urgency, alignment, confidence}.
   * L2â†’L1 **autoâ€‘wake** microâ€‘missions.
   * **Partner DM** path for one partner/channel with ACK/clarify.
   * Observability tiles in Iris: *Intents today*, *Autonomy levels*, *Telegram SLA*, *Outcome quality*.

3. **Phaseâ€‘B:**

   * Add errors/logs/repo events as stimuli.
   * Full PoG/PoC/PoP learning, graduated autonomy to L3 with sandbox actions and PRs.
   * Entityâ€‘first WM and betweenâ€‘entity jumps integrated.

4. **Phaseâ€‘C:**

   * Perâ€‘org citizens (consultancy template).
   * Distillation to N3 and policyâ€‘driven knowledge sharing.
   * Quarantine + killâ€‘switch sentinels tuned on real incidents.

---

## 11) Why this is the right way *now*

* It **aligns cognition** (entities/WM/chunks) with **operations** (intents/priorities/verification).
* It **eliminates constants**, so it wonâ€™t rot when the org grows or the signal mix changes.
* It gives you **fast value in safe domains** (Telegram, docs, PRs) and a *principled path* to deeper autonomy.
* And crucially: it remains **auditable**. If autonomy ever goes wrong, we can *see exactly why* and teach the system not to repeat it.

If you want, I can turn this into the three docs listed in Â§10 with exact field names and event payloads so Felix can wire the orchestrator and Iris can render the new panels without guessing.
