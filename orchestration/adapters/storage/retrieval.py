"""
Retrieval Module - Read Flux (Blue Arrow) Implementation

This module implements the "Read Flux" - the ability for Couche 3 (Mind) to retrieve
relevant consciousness context from multi-level memory (N1/N2/N3) via parallel hybrid queries.

Flow:
1. Couche 3 generates RetrievalIntention (via S6 autonomous energy or explicit request)
2. Orchestrator executes 6 parallel queries (N1/N2/N3 � vector/graph)
3. Temporal filtering applied via Phase 2 bitemporal logic
4. Results assembled into ConsciousnessStream with full consciousness metadata
5. Stream returned to Couche 3 for response formulation

Designer: Felix (Engineer) implementing Ada's Architecture
Phase: 3 - Retrieval Flux (Read Flux / Blue Arrow)
Architecture: docs/specs/consciousness_substrate_guide.md (integrated guide by Luca + Ada)
API Reference: docs/specs/retrieval_api_reference.md
Date: 2025-10-17
"""

import sys
from pathlib import Path
from typing import List, Dict, Any, Optional, Literal, Tuple
from datetime import datetime
import asyncio
import json

# Add substrate to path for schema imports
sys.path.insert(0, str(Path(__file__).parent.parent / "substrate"))

# Import Ada's schemas
from substrate.schemas.consciousness_schema import NODE_TYPES, RELATION_TYPES

# Import serialization layer for deserialization (FalkorDB stores complex fields as JSON strings)
from substrate.schemas.serialization import deserialize_node_from_falkordb, deserialize_relation_from_falkordb

# Import FalkorDB for graph queries
from llama_index.graph_stores.falkordb import FalkorDBGraphStore

# Import our custom LLM wrapper for subentity extraction
from orchestration.libs.custom_claude_llm import create_claude_llm

# Pydantic imports
from pydantic import BaseModel, Field


# ============================================================================
# Component 1: Intention Specification (from Ada's architecture)
# ============================================================================

class RetrievalIntention(BaseModel):
    """
    Structured request for consciousness context retrieval.

    Generated by Couche 3 Subentity Ecology (via S6 autonomous energy
    or explicit context request).
    """

    # Core query
    query_text: str = Field(
        description="Natural language description of needed context"
    )

    # Temporal parameters
    temporal_mode: Literal["current", "point_in_time", "evolution", "full_history"] = "current"
    as_of_time: Optional[datetime] = None  # For point_in_time queries
    time_range_start: Optional[datetime] = None  # For evolution/full_history
    time_range_end: Optional[datetime] = None

    # Level filtering (ARCHITECTURAL DECISION #1: default query all levels)
    query_levels: List[Literal["N1", "N2", "N3"]] = ["N1", "N2", "N3"]

    # Result limits
    max_results_per_level: int = 20  # Top-K for each of 6 queries

    # Consciousness filtering
    min_activity: Optional[float] = None  # Filter low-activity memories (energy-only model)
    min_confidence: Optional[float] = None  # Filter uncertain beliefs
    required_emotions: Optional[List[str]] = None  # e.g., ["excitement", "caution"]

    # Citizen context
    citizen_id: str = Field(description="Which citizen's consciousness to query")

    # Metadata
    intention_id: str = Field(description="Unique identifier for this retrieval")
    generated_at: datetime = Field(default_factory=datetime.utcnow)
    generated_by: str = Field(description="Which subentity/context generated this")


# ============================================================================
# Component 4: Consciousness Stream Format (from Ada's architecture)
# ============================================================================

class ConsciousnessNode(BaseModel):
    """A single node with full consciousness metadata."""

    # Core idsubentity
    node_id: str
    node_type: str  # Memory, Decision, Person, etc.
    name: str
    description: str

    # Temporal metadata (Phase 2 bitemporal)
    valid_at: datetime
    invalid_at: Optional[datetime] = None
    created_at: datetime
    expired_at: Optional[datetime] = None

    # Consciousness metadata (from consciousness_schema.py - energy-only model)
    energy: float = Field(ge=0.0, le=1.0, default=0.0, description="Current activation energy (dynamic, decays)")
    weight: float = Field(ge=0.0, le=1.0, default=0.5, description="Static importance (how central this pattern is)")
    confidence: float = Field(ge=0.0, le=1.0, default=0.5)
    emotion_vector: Optional[Dict[str, float]] = None
    felt_quality: Optional[str] = None
    body_sensation: Optional[str] = None

    # Retrieval metadata
    retrieval_source: str  # "N1_vector" or "N2_graph" etc.
    relevance_score: float


class ConsciousnessRelationship(BaseModel):
    """A relationship with consciousness metadata."""

    # Idsubentity
    source_id: str
    target_id: str
    relation_type: str  # JUSTIFIES, ENABLES, etc.

    # Consciousness metadata (REQUIRED on all relations - energy-only model)
    goal: str
    mindstate: str
    confidence: float = Field(ge=0.0, le=1.0, default=0.5)
    formation_trigger: str
    emotion_vector: Optional[Dict[str, float]] = None

    # Note: Energy tracked on nodes (energy), not relations

    # Temporal
    valid_at: datetime
    invalid_at: Optional[datetime] = None
    created_at: datetime
    expired_at: Optional[datetime] = None


class ConsciousnessLevelResults(BaseModel):
    """Results from one level (N1, N2, or N3)."""

    vector_results: List[ConsciousnessNode] = []
    graph_results: List[ConsciousnessNode] = []
    relationships: List[ConsciousnessRelationship] = []  # From graph traversal


class ConsciousnessSummary(BaseModel):
    """High-level analysis of retrieved context."""

    # Aggregate consciousness state
    dominant_activity: float = Field(description="Average activity level across all results (energy-only model)")
    emotional_themes: List[str] = Field(description="Most common emotions")
    confidence_average: float = Field(description="Average confidence")

    # Temporal span
    earliest_memory: datetime
    latest_memory: datetime

    # Level distribution
    n1_result_count: int
    n2_result_count: int
    n3_result_count: int

    # Quality metrics
    total_results: int
    active_vs_historical_ratio: float  # % of results that are currently active


class ConsciousnessStream(BaseModel):
    """
    The complete consciousness stream returned to Couche 3.

    This is what the Mind receives to formulate responses and reason.
    """

    # Metadata
    intention_id: str
    retrieved_at: datetime

    # Multi-level results
    levels: Dict[str, ConsciousnessLevelResults] = Field(
        description="Keys: 'n1_personal', 'n2_collective', 'n3_ecosystem'"
    )

    # Summary analysis
    consciousness_summary: ConsciousnessSummary

    # Query performance metadata
    retrieval_latency_ms: Optional[int] = None
    query_count: int = 6  # Always 6 parallel queries


# ============================================================================
# Component 2: Temporal Filter Generation (Phase 2 Integration)
# ============================================================================

def generate_temporal_filter(
    temporal_mode: str,
    as_of_time: Optional[datetime] = None
) -> str:
    """
    Generate Cypher WHERE clause for temporal filtering.

    Uses Phase 2 bitemporal pattern (valid_at/invalid_at, created_at/expired_at).

    This is where Ada's bitemporal logic integrates into retrieval.
    """

    if temporal_mode == "current":
        # Active facts: both valid in reality AND known to consciousness
        # Using ISO string comparison (FalkorDB doesn't support datetime() function)
        now = datetime.utcnow().isoformat()
        return f"""
            (node.invalid_at IS NULL OR node.invalid_at > '{now}')
            AND (node.expired_at IS NULL OR node.expired_at > '{now}')
        """

    elif temporal_mode == "point_in_time":
        # State at specific moment
        # Using ISO string comparison (FalkorDB doesn't support datetime() function)
        if not as_of_time:
            raise ValueError("point_in_time mode requires as_of_time parameter")

        as_of_iso = as_of_time.isoformat()
        return f"""
            node.valid_at <= '{as_of_iso}'
            AND (node.invalid_at IS NULL OR node.invalid_at > '{as_of_iso}')
            AND node.created_at <= '{as_of_iso}'
            AND (node.expired_at IS NULL OR node.expired_at > '{as_of_iso}')
        """

    elif temporal_mode == "evolution":
        # All versions within time range (for tracking belief changes)
        # NO temporal filtering - retrieve all, post-process with track_evolution()
        return "true"  # No filter

    elif temporal_mode == "full_history":
        # Everything ever known (for complete historical reconstruction)
        return "true"

    else:
        raise ValueError(f"Unknown temporal_mode: {temporal_mode}")


# ============================================================================
# Component 2: Vector Search Implementation
# ============================================================================

async def vector_search(
    query_embedding: List[float],
    graph_name: str,  # "citizen_Luca" (N1) or "collective_n2" or "ecosystem_n3"
    level_name: str,  # "N1", "N2", or "N3"
    intention: RetrievalIntention,
    falkordb_host: str = "localhost",
    falkordb_port: int = 6379
) -> List[Dict[str, Any]]:
    """
    Semantic similarity search using FalkorDB native vectors.

    Returns top-K nodes ranked by cosine similarity to query embedding.
    """

    print(f"[VectorSearch/{level_name}] Starting for graph: {graph_name}")

    try:
        # Connect to FalkorDB graph
        falkordb_url = f"redis://{falkordb_host}:{falkordb_port}"
        graph_store = FalkorDBGraphStore(
            graph_name=graph_name,
            url=falkordb_url
        )

        # Generate temporal filter clause
        temporal_cypher = generate_temporal_filter(
            intention.temporal_mode,
            intention.as_of_time
        )

        # FalkorDB Native Vector Search
        # Signature: db.idx.vector.queryNodes(label, attribute, k, vecf32(query))
        # NOTE: FalkorDB requires querying specific labels, so we union across all node types
        # This is architectural - we have 44 different node types, not a single "Node" label

        # Convert embedding list to vecf32 format for FalkorDB
        # FalkorDB expects: vecf32([float, float, ...])
        embedding_str = str(query_embedding)

        # Build union query across all possible node labels
        # We query top K from each label, then sort and limit to overall top K
        cypher_query = f"""
        CALL db.idx.vector.queryNodes(
            'Node',          // All nodes have :Node label for vector search
            'embedding',     // Attribute name
            {intention.max_results_per_level * 3},  // Get extra results before filtering
            vecf32({embedding_str})
        ) YIELD node, score
        WHERE {temporal_cypher}
        RETURN
            id(node) AS node_id,
            node.name AS name,
            node.description AS description,
            labels(node)[0] AS node_type,
            node.valid_at AS valid_at,
            node.invalid_at AS invalid_at,
            node.created_at AS created_at,
            node.expired_at AS expired_at,
            node.energy AS energy,
            node.weight AS weight,
            node.confidence AS confidence,
            node.emotion_vector AS emotion_vector,
            node.felt_quality AS felt_quality,
            node.body_sensation AS body_sensation,
            score
        ORDER BY score DESC
        LIMIT {intention.max_results_per_level}
        """

        # Execute native vector search query
        raw_results = graph_store.query(cypher_query)

        # Convert list results to dictionaries
        # FalkorDB returns results as lists matching RETURN order
        field_names = [
            "node_id", "name", "description", "node_type",
            "valid_at", "invalid_at", "created_at", "expired_at",
            "energy", "weight", "confidence", "emotion_vector",
            "felt_quality", "body_sensation", "score"
        ]

        results = []
        for raw_result in raw_results:
            result_dict = {field_names[i]: raw_result[i] for i in range(len(field_names))}
            result_dict["_source"] = f"{level_name}_vector"
            results.append(result_dict)

        print(f"[VectorSearch/{level_name}] Retrieved {len(results)} results")
        return results

    except Exception as e:
        print(f"[ERROR] VectorSearch/{level_name} failed: {str(e)}")
        return []


# ============================================================================
# Component 2: Graph Traversal Implementation
# ============================================================================

async def extract_entities_from_query(
    query_text: str,
    llm: Any
) -> List[str]:
    """
    Extract subentity names from query text using LLM.

    Uses few-shot prompting with schema awareness.
    """

    print(f"[EntityExtraction] Extracting subentities from query...")

    prompt = f"""
    Extract subentity names from this query that might exist in a consciousness graph.

    Query: {query_text}

    Return subentity names as a JSON array of strings.

    Example:
    Query: "How does Luca's approach to V2 differ from Felix's?"
    Subentities: ["Luca", "Felix", "V2 architecture"]

    Return ONLY the JSON array, nothing else.
    """

    try:
        response = llm.complete(prompt)
        response_text = response.text.strip()

        # Debug: Show what LLM returned
        print(f"[EntityExtraction] LLM response length: {len(response_text)} chars")

        if not response_text:
            print(f"[ERROR] Subentity extraction: LLM returned empty response")
            return []

        # Clean potential markdown code blocks
        if response_text.startswith("```"):
            response_text = response_text.split("```")[1]
            if response_text.startswith("json"):
                response_text = response_text[4:]
            response_text = response_text.strip()

        subentities = json.loads(response_text)
        print(f"[EntityExtraction] Extracted subentities: {subentities}")
        return subentities
    except json.JSONDecodeError as e:
        print(f"[ERROR] Subentity extraction JSON parse failed: {str(e)}")
        print(f"[ERROR] Response was: {response_text[:200] if response_text else '(empty)'}")
        return []
    except Exception as e:
        print(f"[ERROR] Subentity extraction failed: {str(e)}")
        return []


async def graph_traversal(
    query_text: str,
    graph_name: str,
    level_name: str,  # "N1", "N2", or "N3"
    intention: RetrievalIntention,
    llm: Any,
    falkordb_host: str = "localhost",
    falkordb_port: int = 6379
) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
    """
    Relationship-based traversal from subentities identified in query.

    Steps:
    1. Extract subentities from query_text via LLM
    2. Start traversal from those subentities (parallel)
    3. Follow relationships to depth=2
    4. Apply temporal filters
    5. Rank by relationship strength + consciousness metadata

    Returns: (nodes, relationships)
    """

    print(f"[GraphTraversal/{level_name}] Starting for graph: {graph_name}")

    try:
        # Step 1: Extract subentities via LLM
        subentities = await extract_entities_from_query(query_text, llm)

        if not subentities:
            print(f"[GraphTraversal/{level_name}] No subentities extracted, skipping")
            return [], []

        # Connect to FalkorDB graph
        falkordb_url = f"redis://{falkordb_host}:{falkordb_port}"
        graph_store = FalkorDBGraphStore(
            graph_name=graph_name,
            url=falkordb_url
        )

        # Generate temporal filter
        temporal_cypher = generate_temporal_filter(
            intention.temporal_mode,
            intention.as_of_time
        )

        # Multi-subentity traversal Cypher (ARCHITECTURAL DECISION #3)
        cypher_query = f"""
        MATCH (start)
        WHERE start.name IN $entity_names
          AND ({temporal_cypher.replace('node.', 'start.')})

        // Traverse relationships to depth 2
        MATCH path = (start)-[r*1..2]-(connected)
        WHERE ({temporal_cypher.replace('node.', 'connected.')})

        // Rank by relationship strength and consciousness metadata (energy-only model)
        WITH connected, path,
             // Energy contribution: node activity + weight
             COALESCE(connected.energy, 0.0) AS node_activity,
             COALESCE(connected.weight, 0.5) AS node_weight,
             // Confidence contribution from relationships
             reduce(conf = 0.0, rel IN relationships(path) | conf + COALESCE(rel.confidence, 0.5)) AS path_confidence,
             // Path length penalty
             length(path) AS depth

        RETURN DISTINCT
            id(connected) AS node_id,
            connected.name AS name,
            connected.description AS description,
            labels(connected)[0] AS node_type,
            connected.valid_at AS valid_at,
            connected.invalid_at AS invalid_at,
            connected.created_at AS created_at,
            connected.expired_at AS expired_at,
            connected.energy AS energy,
            connected.weight AS weight,
            connected.confidence AS confidence,
            connected.emotion_vector AS emotion_vector,
            connected.felt_quality AS felt_quality,
            connected.body_sensation AS body_sensation,
            node_activity,
            node_weight,
            path_confidence,
            depth
        ORDER BY node_weight DESC, node_activity DESC, path_confidence DESC, depth ASC
        LIMIT $max_results
        """

        # Execute node query
        raw_node_results = graph_store.query(
            cypher_query,
            params={
                "entity_names": subentities,
                "max_results": intention.max_results_per_level
            }
        )

        # Convert list results to dictionaries
        node_field_names = [
            "node_id", "name", "description", "node_type",
            "valid_at", "invalid_at", "created_at", "expired_at",
            "energy", "weight", "confidence", "emotion_vector",
            "felt_quality", "body_sensation",
            "node_activity", "node_weight", "path_confidence", "depth"
        ]

        node_results = []
        for raw_result in raw_node_results:
            result_dict = {node_field_names[i]: raw_result[i] for i in range(len(node_field_names))}
            result_dict["_source"] = f"{level_name}_graph"
            # Energy-only model: score = weight (static importance) + activity (dynamic energy)
            weight_val = result_dict.get("node_weight", 0.5)
            activity_val = result_dict.get("node_activity", 0.0)
            result_dict["score"] = (weight_val * 0.6) + (activity_val * 0.4)  # Weight matters more
            node_results.append(result_dict)

        # Fetch relationships for returned nodes
        if node_results:
            node_ids = [r["node_id"] for r in node_results]

            relationship_query = """
            MATCH (source)-[r]->(target)
            WHERE id(source) IN $node_ids
              AND id(target) IN $node_ids
            RETURN
                id(source) AS source_id,
                id(target) AS target_id,
                type(r) AS relation_type,
                r.goal AS goal,
                r.mindstate AS mindstate,
                r.confidence AS confidence,
                r.formation_trigger AS formation_trigger,
                r.emotion_vector AS emotion_vector,
                r.valid_at AS valid_at,
                r.invalid_at AS invalid_at,
                r.created_at AS created_at,
                r.expired_at AS expired_at
            """

            raw_relationship_results = graph_store.query(
                relationship_query,
                params={"node_ids": node_ids}
            )

            # Convert list results to dictionaries (energy-only model: no energy on relations)
            rel_field_names = [
                "source_id", "target_id", "relation_type", "goal", "mindstate",
                "confidence", "formation_trigger",
                "emotion_vector", "valid_at", "invalid_at", "created_at", "expired_at"
            ]

            relationship_results = []
            for raw_result in raw_relationship_results:
                result_dict = {rel_field_names[i]: raw_result[i] for i in range(len(rel_field_names))}
                relationship_results.append(result_dict)
        else:
            relationship_results = []

        print(f"[GraphTraversal/{level_name}] Retrieved {len(node_results)} nodes, {len(relationship_results)} relationships")
        return node_results, relationship_results

    except Exception as e:
        print(f"[ERROR] GraphTraversal/{level_name} failed: {str(e)}")
        return [], []


# ============================================================================
# Component 3: Result Assembly (Pure Concatenation - ARCHITECTURAL DECISION #4)
# ============================================================================

def enrich_with_consciousness_metadata(
    raw_results: List[Dict[str, Any]],
    retrieval_source: str
) -> List[ConsciousnessNode]:
    """
    Transform raw FalkorDB results into ConsciousnessNode objects.

    Ensures all consciousness metadata is present and properly formatted.
    Deserializes JSON string fields back to dicts (FalkorDB stores complex fields as JSON).
    """

    enriched = []

    for result in raw_results:
        try:
            # CRITICAL: Deserialize FalkorDB data (JSON strings back to dicts)
            # This reverses the serialization done in insertion.py
            node_type = result.get("node_type", "Unknown")
            deserialized_result = deserialize_node_from_falkordb(result, node_type)

            # Convert node_id to string (FalkorDB returns integers)
            node_id_value = deserialized_result.get("node_id", "")
            node_id_str = str(node_id_value) if node_id_value is not None else ""

            # Energy-only model: energy + weight (no energy)
            activity = deserialized_result.get("energy")
            activity_value = float(activity) if activity is not None else 0.0

            weight = deserialized_result.get("weight")
            weight_value = float(weight) if weight is not None else 0.5

            confidence = deserialized_result.get("confidence")
            confidence_value = float(confidence) if confidence is not None else 0.5

            node = ConsciousnessNode(
                node_id=node_id_str,
                node_type=node_type,
                name=deserialized_result.get("name", ""),
                description=deserialized_result.get("description", ""),

                # Temporal
                valid_at=deserialized_result.get("valid_at", datetime.utcnow()),
                invalid_at=deserialized_result.get("invalid_at"),
                created_at=deserialized_result.get("created_at", datetime.utcnow()),
                expired_at=deserialized_result.get("expired_at"),

                # Consciousness (energy-only model - properly deserialized)
                energy=activity_value,
                weight=weight_value,
                confidence=confidence_value,
                emotion_vector=deserialized_result.get("emotion_vector"),
                felt_quality=deserialized_result.get("felt_quality"),
                body_sensation=deserialized_result.get("body_sensation"),

                # Retrieval
                retrieval_source=retrieval_source,
                relevance_score=deserialized_result.get("score", 0.0)
            )

            enriched.append(node)
        except Exception as e:
            print(f"[ERROR] Failed to enrich node: {str(e)}")
            continue

    return enriched


def enrich_relationships(
    raw_relationships: List[Dict[str, Any]]
) -> List[ConsciousnessRelationship]:
    """
    Transform raw relationship results into ConsciousnessRelationship objects.

    Deserializes JSON string fields back to dicts (FalkorDB stores complex fields as JSON).
    """

    enriched = []

    for rel in raw_relationships:
        try:
            # CRITICAL: Deserialize FalkorDB data (JSON strings back to dicts)
            # This reverses the serialization done in insertion.py
            relation_type = rel.get("relation_type", "RELATES_TO")
            deserialized_rel = deserialize_relation_from_falkordb(rel, relation_type)

            relationship = ConsciousnessRelationship(
                source_id=str(deserialized_rel.get("source_id", "")),
                target_id=str(deserialized_rel.get("target_id", "")),
                relation_type=relation_type,

                # Consciousness metadata (energy-only model: no energy on relations)
                goal=deserialized_rel.get("goal", "Unknown goal"),
                mindstate=deserialized_rel.get("mindstate", "Unknown mindstate"),
                confidence=deserialized_rel.get("confidence", 0.5),
                formation_trigger=deserialized_rel.get("formation_trigger", "Unknown trigger"),
                emotion_vector=deserialized_rel.get("emotion_vector"),

                # Temporal
                valid_at=deserialized_rel.get("valid_at", datetime.utcnow()),
                invalid_at=deserialized_rel.get("invalid_at"),
                created_at=deserialized_rel.get("created_at", datetime.utcnow()),
                expired_at=deserialized_rel.get("expired_at")
            )

            enriched.append(relationship)
        except Exception as e:
            print(f"[ERROR] Failed to enrich relationship: {str(e)}")
            continue

    return enriched


def generate_consciousness_summary(
    all_results: List[List[ConsciousnessNode]]
) -> ConsciousnessSummary:
    """
    Generate high-level analysis of retrieved context.

    Analyzes aggregate consciousness state, temporal span, level distribution.
    """

    # Flatten all results
    all_nodes = [node for result_set in all_results for node in result_set]

    if not all_nodes:
        # Return default summary if no results
        return ConsciousnessSummary(
            dominant_activity=0.0,
            emotional_themes=[],
            confidence_average=0.5,
            earliest_memory=datetime.utcnow(),
            latest_memory=datetime.utcnow(),
            n1_result_count=0,
            n2_result_count=0,
            n3_result_count=0,
            total_results=0,
            active_vs_historical_ratio=1.0
        )

    # Calculate aggregate consciousness metrics (energy-only model)
    avg_activity = sum(n.energy for n in all_nodes) / len(all_nodes)
    avg_confidence = sum(n.confidence for n in all_nodes) / len(all_nodes)

    # Extract emotional themes
    emotion_counts: Dict[str, int] = {}
    for node in all_nodes:
        if node.emotion_vector:
            for emotion in node.emotion_vector.keys():
                emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1

    top_emotions = sorted(emotion_counts.items(), key=lambda x: x[1], reverse=True)[:5]
    emotional_themes = [emotion for emotion, _ in top_emotions]

    # Temporal span
    valid_at_times = [n.valid_at for n in all_nodes]
    earliest = min(valid_at_times)
    latest = max(valid_at_times)

    # Level distribution
    n1_count = sum(1 for n in all_nodes if n.retrieval_source.startswith("N1"))
    n2_count = sum(1 for n in all_nodes if n.retrieval_source.startswith("N2"))
    n3_count = sum(1 for n in all_nodes if n.retrieval_source.startswith("N3"))

    # Active vs historical ratio
    now = datetime.utcnow()
    active_count = sum(
        1 for n in all_nodes
        if (n.invalid_at is None or n.invalid_at > now)
        and (n.expired_at is None or n.expired_at > now)
    )
    active_ratio = active_count / len(all_nodes) if all_nodes else 1.0

    return ConsciousnessSummary(
        dominant_activity=avg_activity,
        emotional_themes=emotional_themes,
        confidence_average=avg_confidence,
        earliest_memory=earliest,
        latest_memory=latest,
        n1_result_count=n1_count,
        n2_result_count=n2_count,
        n3_result_count=n3_count,
        total_results=len(all_nodes),
        active_vs_historical_ratio=active_ratio
    )


def assemble_consciousness_stream(
    n1_vector_results: List[Dict[str, Any]],
    n1_graph_nodes: List[Dict[str, Any]],
    n1_graph_relationships: List[Dict[str, Any]],
    n2_vector_results: List[Dict[str, Any]],
    n2_graph_nodes: List[Dict[str, Any]],
    n2_graph_relationships: List[Dict[str, Any]],
    n3_vector_results: List[Dict[str, Any]],
    n3_graph_nodes: List[Dict[str, Any]],
    n3_graph_relationships: List[Dict[str, Any]],
    intention: RetrievalIntention
) -> ConsciousnessStream:
    """
    Assemble consciousness stream via simple concatenation.

    Order: Vector results first (semantic context), then graph results (relational context)
    Within each: N1 (personal) � N2 (organization) � N3 (ecosystem)

    ARCHITECTURAL DECISION #4: Pure concatenation, let LLM synthesize.
    """

    print(f"[Assembly] Assembling consciousness stream...")

    # Enrich all results with consciousness metadata
    n1_vec = enrich_with_consciousness_metadata(n1_vector_results, "N1_vector")
    n1_graph = enrich_with_consciousness_metadata(n1_graph_nodes, "N1_graph")
    n1_rels = enrich_relationships(n1_graph_relationships)

    n2_vec = enrich_with_consciousness_metadata(n2_vector_results, "N2_vector")
    n2_graph = enrich_with_consciousness_metadata(n2_graph_nodes, "N2_graph")
    n2_rels = enrich_relationships(n2_graph_relationships)

    n3_vec = enrich_with_consciousness_metadata(n3_vector_results, "N3_vector")
    n3_graph = enrich_with_consciousness_metadata(n3_graph_nodes, "N3_graph")
    n3_rels = enrich_relationships(n3_graph_relationships)

    # Create level results
    levels = {
        "n1_personal": ConsciousnessLevelResults(
            vector_results=n1_vec,
            graph_results=n1_graph,
            relationships=n1_rels
        ),
        "n2_collective": ConsciousnessLevelResults(
            vector_results=n2_vec,
            graph_results=n2_graph,
            relationships=n2_rels
        ),
        "n3_ecosystem": ConsciousnessLevelResults(
            vector_results=n3_vec,
            graph_results=n3_graph,
            relationships=n3_rels
        )
    }

    # Generate consciousness summary
    all_node_results = [n1_vec, n1_graph, n2_vec, n2_graph, n3_vec, n3_graph]
    summary = generate_consciousness_summary(all_node_results)

    # Assemble stream
    stream = ConsciousnessStream(
        intention_id=intention.intention_id,
        retrieved_at=datetime.utcnow(),
        levels=levels,
        consciousness_summary=summary
    )

    print(f"[Assembly] Stream assembled: {summary.total_results} total results")
    print(f"  N1: {summary.n1_result_count}, N2: {summary.n2_result_count}, N3: {summary.n3_result_count}")
    print(f"  Dominant activity: {summary.dominant_activity:.2f}")
    print(f"  Active ratio: {summary.active_vs_historical_ratio:.2%}")

    return stream


# ============================================================================
# Component 2: Main Retrieval Orchestrator (6-Way Parallel Queries)
# ============================================================================

async def generate_embedding(query_text: str) -> List[float]:
    """
    Generate embedding for query text using sentence-transformers.

    Uses: sentence-transformers/all-MiniLM-L6-v2 (384 dimensions)
    - Same model used for backfilling embeddings
    - Local model (no API dependency)
    - Fast inference
    """
    from sentence_transformers import SentenceTransformer

    # Load model (cached after first call)
    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

    print(f"[Embedding] Generating embedding for query: {query_text[:50]}...")
    embedding = model.encode(query_text).tolist()

    return embedding


async def retrieve_consciousness_context(
    intention: RetrievalIntention,
    falkordb_host: str = "localhost",
    falkordb_port: int = 6379,
    claude_working_dir: Optional[str] = None
) -> ConsciousnessStream:
    """
    Main retrieval function - orchestrates 6 parallel queries.

    This is the entry point called by Couche 3 (Mind/Ecology).

    Flow:
    1. Generate query embedding
    2. Execute 6 parallel queries (N1/N2/N3 � vector/graph)
    3. Assemble results into ConsciousnessStream
    4. Return to Couche 3

    ARCHITECTURAL DECISION #1: Query all levels by default (parallel = no latency penalty)
    """

    print(f"\n{'=' * 60}")
    print(f"[Retrieval] Starting for intention: {intention.intention_id}")
    print(f"[Retrieval] Query: {intention.query_text}")
    print(f"[Retrieval] Citizen: {intention.citizen_id}")
    print(f"[Retrieval] Temporal mode: {intention.temporal_mode}")
    print(f"{'=' * 60}\n")

    start_time = datetime.utcnow()

    # Initialize LLM for subentity extraction
    llm = create_claude_llm(
        working_dir=claude_working_dir,
        timeout=60
    )

    # Generate query embedding
    query_embedding = await generate_embedding(intention.query_text)

    # Prepare graph names
    n1_graph = f"citizen_{intention.citizen_id}"
    n2_graph = "collective_n2"
    n3_graph = "ecosystem_n3"

    # Execute 6 parallel queries (ARCHITECTURAL DECISION #1)
    print(f"[Retrieval] Executing 6 parallel queries...")
    results = await asyncio.gather(
        # N1 queries
        vector_search(query_embedding, n1_graph, "N1", intention, falkordb_host, falkordb_port),
        graph_traversal(intention.query_text, n1_graph, "N1", intention, llm, falkordb_host, falkordb_port),

        # N2 queries
        vector_search(query_embedding, n2_graph, "N2", intention, falkordb_host, falkordb_port),
        graph_traversal(intention.query_text, n2_graph, "N2", intention, llm, falkordb_host, falkordb_port),

        # N3 queries
        vector_search(query_embedding, n3_graph, "N3", intention, falkordb_host, falkordb_port),
        graph_traversal(intention.query_text, n3_graph, "N3", intention, llm, falkordb_host, falkordb_port),

        return_exceptions=True  # Don't fail entire retrieval if one query fails
    )

    # Unpack results (graph_traversal returns tuples, vector_search returns lists)
    n1_vec = results[0] if not isinstance(results[0], Exception) else []
    n1_graph_nodes, n1_graph_rels = results[1] if not isinstance(results[1], Exception) else ([], [])

    n2_vec = results[2] if not isinstance(results[2], Exception) else []
    n2_graph_nodes, n2_graph_rels = results[3] if not isinstance(results[3], Exception) else ([], [])

    n3_vec = results[4] if not isinstance(results[4], Exception) else []
    n3_graph_nodes, n3_graph_rels = results[5] if not isinstance(results[5], Exception) else ([], [])

    # Assemble consciousness stream (ARCHITECTURAL DECISION #4: Pure concatenation)
    stream = assemble_consciousness_stream(
        n1_vec, n1_graph_nodes, n1_graph_rels,
        n2_vec, n2_graph_nodes, n2_graph_rels,
        n3_vec, n3_graph_nodes, n3_graph_rels,
        intention
    )

    # Add performance metadata
    end_time = datetime.utcnow()
    stream.retrieval_latency_ms = int((end_time - start_time).total_seconds() * 1000)

    print(f"\n{'=' * 60}")
    print(f"[Retrieval] Complete for intention: {intention.intention_id}")
    print(f"[Retrieval] Latency: {stream.retrieval_latency_ms}ms")
    print(f"[Retrieval] Total results: {stream.consciousness_summary.total_results}")
    print(f"{'=' * 60}\n")

    return stream


# ============================================================================
# Convenience Function (Simple API for Couche 3)
# ============================================================================

async def retrieve_context(
    query_text: str,
    citizen_id: str,
    temporal_mode: str = "current",
    as_of_time: Optional[datetime] = None,
    falkordb_host: str = "localhost",
    falkordb_port: int = 6379,
    claude_working_dir: Optional[str] = None
) -> ConsciousnessStream:
    """
    Simple function for retrieving consciousness context.

    This is the main API for Couche 3 (Hooks/Ecology) to call.

    Args:
        query_text: Natural language query
        citizen_id: Which citizen's consciousness to query
        temporal_mode: "current", "point_in_time", "evolution", or "full_history"
        as_of_time: For point_in_time queries
        falkordb_host: FalkorDB server host
        falkordb_port: FalkorDB server port
        claude_working_dir: Working directory for Claude Code

    Returns:
        ConsciousnessStream with multi-level results

    Example:
        from orchestration.adapters.storage.retrieval import retrieve_context

        stream = await retrieve_context(
            query_text="Tell me about V2 architecture decisions",
            citizen_id="Luca"
        )

        print(f"Retrieved {stream.consciousness_summary.total_results} memories")
        for node in stream.levels["n1_personal"].vector_results:
            print(f"  {node.name}: {node.description}")
    """

    # Create intention
    intention = RetrievalIntention(
        query_text=query_text,
        citizen_id=citizen_id,
        temporal_mode=temporal_mode,
        as_of_time=as_of_time,
        intention_id=f"intention_{datetime.utcnow().isoformat()}",
        generated_by="retrieve_context_api",
        generated_at=datetime.utcnow()
    )

    # Execute retrieval
    return await retrieve_consciousness_context(
        intention=intention,
        falkordb_host=falkordb_host,
        falkordb_port=falkordb_port,
        claude_working_dir=claude_working_dir
    )


# ============================================================================
# Main Entry Point (for testing)
# ============================================================================

if __name__ == "__main__":
    # Quick test when run directly
    print("=" * 60)
    print("CONSCIOUSNESS RETRIEVAL ENGINE - Quick Test")
    print("=" * 60)

    async def test_retrieval():
        """Test basic retrieval."""

        stream = await retrieve_context(
            query_text="Tell me about V2 architecture decisions",
            citizen_id="Luca"
        )

        print("\n" + "=" * 60)
        print(f"[RESULT] Intention: {stream.intention_id}")
        print(f"[RESULT] Latency: {stream.retrieval_latency_ms}ms")
        print(f"[RESULT] Total results: {stream.consciousness_summary.total_results}")
        print(f"[RESULT] N1: {stream.consciousness_summary.n1_result_count}")
        print(f"[RESULT] N2: {stream.consciousness_summary.n2_result_count}")
        print(f"[RESULT] N3: {stream.consciousness_summary.n3_result_count}")
        print(f"[RESULT] Dominant activity: {stream.consciousness_summary.dominant_activity:.2f}")
        print(f"[RESULT] Emotional themes: {stream.consciousness_summary.emotional_themes}")
        print("=" * 60)

    # Run test
    try:
        asyncio.run(test_retrieval())
    except Exception as e:
        print(f"\n[ERROR] Test failed: {str(e)}")
        import traceback
        traceback.print_exc()
